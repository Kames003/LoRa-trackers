Config cez SenseCraft ---> stlaÄit a drzat button pre 3 sec ---> nasledne v advance settings ---> lora nastavut Decice EUI a AppEUI na to Äo je vo wisgate v evente pod ktorÃ½m su pridanÃ© tieto trackers 
OkamÅ¾ite odoslanie lokacie je stlaÄenim akÄneho tlaÄidla 

# ÄŒo je to OTAA 
bezpeÄnostnÃ½ mechanizmus pre pripojenie do LoRaWAN siete 

Ako to funguje ? 

Join request : tracker poÅ¡le Å¾iadosÅ¥ o pripojenie do siete obsahujÃºcu DevUI - unikÃ¡tne idÄko zariadenia a AppEUI

Join accept : network server overi ziadosÅ¥ pomocou AppKey - predsdielanÃ½ kluÄ - odpovedÃ¡ potvrdenim 

GenerovÃ¡nÃ­ session klÃ­ÄÅ¯: Po ÃºspÄ›Å¡nÃ©m pÅ™ijetÃ­ se dynamicky vygenerujÃ­:
* NwkSKey (Network Session Key) - pro Å¡ifrovÃ¡nÃ­ MAC pÅ™Ã­kazÅ¯
* AppSKey (Application Session Key) - pro Å¡ifrovÃ¡nÃ­ aplikaÄnÃ­ch dat

PreÄo zrovna OTAA ? 

BezpeÄnost: Session klÃ­Äe se mÄ›nÃ­ pÅ™i kaÅ¾dÃ©m pÅ™ipojenÃ­ - KeÄ sa tracker vypne a znova sa pripojÃ­ dostane novÃ© session klÃ­Äe 

PrvÃ© pripojenie : 

1. Tracker zapnut â†’ Join Request
2. Network Server â†’ Join Accept
3. VygenerujÃ­ se: NwkSKey_v1, AppSKey_v1
4. Tracker komunikuje s tÄ›mito klÃ­Äi

Tracker se vypne a znovu zapne:

1. Tracker zapnut â†’ NovÃ½ Join Request
2. Network Server â†’ NovÃ½ Join Accept
3. VygenerujÃ­ se: NwkSKey_v2, AppSKey_v2 (JINÃ‰ neÅ¾ v1!)
4. Tracker komunikuje s NOVÃMI klÃ­Äi


MQTT (Message Queuing Telemetry Transport)

je to pub/sub pracuje publishe and subscribe mechanism 

publisher = posiela sprÃ¡vy do toho tematu do nijakeho komunikaÄnÃ©ho kanal

mqqt broker je srdcom mqqt protokolu = zodpovedny za priatie tÃ½chto sprÃ¡v ich prefiltrovanie zistenie who is interested in them a nasledne ich publishnut k subsribe clientom 

v mqqt su tu dve important veci a to sÃº Topic and message and the payload 

topics explains the structure of the datas 
su reprezentovanÃ© stringom a oddelene / ===Shell/A1/Temp 
kazdy / reprezentuje level 
takze budeme maÅ¥ Shell a v nom Area1 mame temperature value 32 

==> takto teda vyzerÃ¡ vstup do mqtt brokera 

takze mqtt bude mat info o vÅ¡etkych publisheroch / clientoch a o ich publikovanÃ½ch informÃ¡ciach 


Subscriber = napr client ktorÃ½ je subscribnutÃ½ k tejto informÃ¡ciÃ­, broker will send the publisher information do toho Å¡pecifickÃ©ho klienta ktorÃ½ mal o nu zaujem  

moze byt viacero odberatelov ktorÃ½ ktorÃ½ pozaduju udaje publishnute z clienta do mqtt brokera 

totoÅ¾ne tak by to fungovalo keby mÃ¡me napr. ÄalÅ¡ieho publishera vytvori novÃ½ entry 

MQTT Topic struktura

# Linux filesystem
/home/user/documents/project/file.txt
  â†“     â†“      â†“        â†“       â†“
root  user  folder  subfolder  file

# MQTT topics
lorawan/trackers/event123/tracker001/location
   â†“       â†“        â†“         â†“         â†“
root   category  event    device    data-type

Pozor lorawan/trackers/event123/tracker001/location je len len virtuÃ¡lny kanal - topic, neexistuje je to len adresa kam sa posielajÃº sprÃ¡vy samotnÃ© mqtt broker si teda len pamatÃ¡ kto sa zaujima o aky topic 

---

CelkovÃ½ dÃ¡tovÃ½ tok nÃ¡Å¡ho projektu 

1. Tracker (T-1000) 
   â†“ [LoRaWAN - OTAA]
2. LoRaWAN Gateway
   â†“ [MQTT publish]
3. MQTT Broker (Mosquitto)
   â†“ [MQTT subscribe]
4. Backend
   - Base64 dekÃ³dovÃ¡nÃ­
   - Parsing payloadu
   - UloÅ¾enÃ­ do DB
   â†“ [WebSocket push]
5. WebovÃ¡ aplikace
   - ZobrazenÃ­ na mapÄ›
   - Real-time aktualizace
   - ÄŒasovÃ¡ osa


aplikovanÃ© pre nÃ¡Å¡ projekt : 


publisher je logicky LoRaWAN brÃ¡na 


Topic: "event/summer-festival/tracker/T1000A-001/uplink"
Payload: 
{
  "payload_raw": "AQIDBAUGBwg=",
  "device_id": "T1000A-001",
  "timestamp": "2025-10-08T14:23:45Z",
  "gateway_id": "gateway-01"
}


MQTT BROKER (Mosquitto):

PÅ™ijme zprÃ¡vu od Gateway
UloÅ¾Ã­ ji do topic struktury
VÃ­, kdo je subscribnutÃ½ na tento topic
PoÅ¡le zprÃ¡vu vÅ¡em subscriberÅ¯m

SUBSCRIBER - backed 
moÅ¾e byt subscriber2 iny klient ktorÃ½ prakticky moze takisto odoberaÅ¥ data napr monitoring / logging systemu samotnÃ©ho 

DÃ¡tovy tok v naÅ¡om projekte by sa dal opÃ­saÅ¥ i nijako takto : 


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tracker   â”‚ (T-1000A, T-1000B)
â”‚  (LoRaWAN)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ LoRaWAN payload
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LoRaWAN Gateway â”‚ (PUBLISHER)
â”‚      (4G)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ MQTT Publish
       â”‚ Topic: event/{id}/tracker/{device}/uplink
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MQTT Broker     â”‚ (Mosquitto)
â”‚   (centrÃ¡lnÃ­)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ MQTT Subscribe
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“         â†“        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend â”‚ â”‚ Logger â”‚ â”‚ Monitor â”‚
â”‚  (tvÅ¯j) â”‚ â”‚        â”‚ â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Wildcards v MQTT 

wildcars su ako * v Linuxe 

/home/*/documents  == je tam tam hviezdiÄka berie akehokovlek jedneho uzivatela 

subscribe('lorawan/trackers/event123/+/location')

// DostaneÅ¡ zprÃ¡vy z:
âœ“ lorawan/trackers/event123/tracker001/location
âœ“ lorawan/trackers/event123/tracker002/location
âœ“ lorawan/trackers/event123/tracker999/location

// NEDOSTANEÅ  zprÃ¡vy z:
âœ— lorawan/trackers/event123/location              â† chybÃ­ ÃºroveÅˆ
âœ— lorawan/trackers/event123/tracker001/battery    â† jinÃ¡ koncovka
âœ— lorawan/trackers/event456/tracker001/location   â† jinÃ½ event

SINGLE WILDCARDS == + 

// Chci vÅ¡echny trackery z konkrÃ©tnÃ­ho eventu
subscribe('lorawan/trackers/event123/+/location')

// Chci konkrÃ©tnÃ­ tracker ze vÅ¡ech eventÅ¯
subscribe('lorawan/trackers/+/tracker001/location')

// Chci vÅ¡echny trackery ze vÅ¡ech eventÅ¯
subscribe('lorawan/trackers/+/+/location')

= Nahrazuje JEDNU nebo VÃCE ÃºrovnÃ­ (zbytek stromu)

# Analogie v Linuxu:
/home/alice/**        # VÅ¡echno pod /home/alice (rekurzivnÄ›)
  âœ“ /home/alice/documents
  âœ“ /home/alice/photos
  âœ“ /home/alice/photos/vacation/2025
  âœ“ /home/alice/deep/nested/structure/file.txt

subscribe('lorawan/trackers/event123/#')

// DostaneÅ¡ VÅ ECHNY zprÃ¡vy pod event123:
âœ“ lorawan/trackers/event123/tracker001/location
âœ“ lorawan/trackers/event123/tracker001/battery
âœ“ lorawan/trackers/event123/tracker001/status/online
âœ“ lorawan/trackers/event123/tracker002/location
âœ“ lorawan/trackers/event123/config/update
âœ“ lorawan/trackers/event123/stats/active-devices

--- 

GPS komplikÃ¡cie 
pri frekvenciÃ­ 1.5 GHz tu blokuje i sklo stena strom 
sklo okna blokuje GPS signÃ¡l minimÃ¡lne o 50 - 80 percent 
budova odrÃ¡Å¾a signal 
satelity musia maÅ¥ priamy vÃ½hÄ¾ad 
gps antÃ©na je smerovanÃ¡ dole 
cold start trv=a dlho 
SignÃ¡l je vÃ½borny RSSI: -42 dBm, SNR: 13.5 dB
GPS scan time bol prÃ­liÅ¡ krÃ¡tky - 60s nestaÄilo tak som ho rozÅ¡Ã­ril v configu appky na 120 

Battery: 50%
Firmware: 2.5
Hardware: 1.6
Work Mode: 1 (Periodic Mode) âœ…
Positioning Strategy: 0 (GPS Only) âœ…
Heartbeat Interval: 720 min
Periodic Interval: 5 min âœ…
Event Interval: 60 min

"errMessage": "FAILED TO OBTAIN THE UTC TIMESTAMP"

Tracker odosiela 2 typy sprÃ¡v cez fPort 5 
sprÃ¡va bez gps - heartbeat 

{
  "Battery": 49%,
  "Firmware": "2.5",
  "Work Mode": 1,
  ...
}
  
GPS sprÃ¡va (s pozÃ­ciou)

{
  "Latitude": 49.821644,
  "Longitude": 18.161606,
  "Battery": 52%,
  "timestamp": ...
}

1. Tracker (T-1000-B)
   â†“ [LoRaWAN OTAA, 868 MHz]
   
2. WisGate Edge Pro (LoRaWAN Gateway)
   â†“ [4G/LTE â†’ Internet]
   â†“ [MQTT publish na port 8883/TLS]
   
3. MQTT Broker (mqtt.hedurio.com)
   â†“ [Topic: application/SENSECAP/#]
   
4. Backend (Python Flask + Flask-SocketIO)
   â”œâ”€ MQTT Client (subscribe)
   â”‚  â†“ PrÃ­jme sprÃ¡vu
   â”‚  â†“ DekÃ³duje Base64 â†’ JSON
   â”‚  â†“ Parse GPS sÃºradnice (lat, lon)
   â”‚  â†“ UloÅ¾Ã­ do PostgreSQL
   â”‚  â†“
   â”œâ”€ WebSocket Server (Flask-SocketIO)
   â”‚  â†“ Broadcast 'tracker-update' event
   â”‚  â†“
   â””â”€ REST API
      â”œâ”€ GET /api/trackers
      â”œâ”€ GET /api/tracker/:id
      â””â”€ GET /api/tracker/:id/history
   
5. Frontend (React + Leaflet.js)
   â”œâ”€ WebSocket Client (Socket.IO-client)
   â”‚  â†“ PoÄÃºva 'tracker-update' event
   â”‚  â†“ Aktualizuje state
   â”‚  â†“
   â”œâ”€ Mapa (Leaflet.js)
   â”‚  â†“ Vykresli markery
   â”‚  â†“ Real-time update pozÃ­ciÃ­
   â”‚  â†“
   â””â”€ Timeline Slider
      â†“ HTTP GET /api/tracker/:id/history?from=X&to=Y
      â†“ ZobrazÃ­ historickÃ© pozÃ­cie


OTAA pri Å¡tate kazdeho join requestu sa vygeneruju dva zakladne seshion kluÄe - network session key - network session key - NwkSkey a application session key AppsKey 

1. vychodiskove parametre v zariadeni ED - End Device napr, Äo je v naÅ¡om trackery 

DevEUI - 64 bit unikatne ID zariadenia 
JoinEUI - AppEUI - 64 bitove ID aplikacie 
AppKey  - 128 bitovy root kluÄ - musi ostat v sieti a v zariadeni v tajnosti 

Join request 

z End device na network server 

tracker vygeneruje 16 bitovy devNonce - je to nahodne Äislo zamedzi replay utokom 
+ do join requestu ramca zapÃ­Å¡e : JoinEUI, DevEUI, DevNonce + poÄÃ­ta CRC - MIC 

toto poÅ¡le do gateway -- network server 

ak je join request validny 

do join accept ramca zabali JoinNonce, DevAddr, DLSettings --> AktorÃ½ je nÃ¡sledne ES-ENCRYPTovanÃ½ kÄ¾ÃºÄom AppKey:

ED ho prijme, decryptuje (rovnakÃ½ AppKey) a preÄÃ­ta JoinNonce, DevAddr atÄ.

ÃºÄel kluÄov 

NwkSKey : 

overovanie a ochranu mac vrsty 
signuje / vypoÄÃ­tava vÅ¡etky uplink aj downlink sprÃ¡vy 
Å¡ifruje a deÅ¡ifruje len sieÅ¥ove prÃ­kazy (FOpts) alebo payload, ak FPort=0


Application session key 

vÃ½hradne na end to end Å¡ifrovanie aplikaÄnÃ½ch dat 
zaÅ¡ifruje frmpayload pri FPort greater than 1 na uplinku aj downlinku 
â€¢ SieÅ¥ (NS) iba preposiela zaÅ¡ifrovanÃ© dÃ¡ta aplikaÄnÃ©mu serveru, ten ich deÅ¡ifruje pomocou AppSKey

mosquitto_sub -h mqtt.hedurio.com -u hedurio -P qn3nyMYUPHTiigLrV94JRiAUXauE9F -t 'application/#' -v -p 8883

prikaz otvorÃ­ MQTTâ€subscriber na heduriackom brokri a vypÃ­Å¡e ti do terminÃ¡lu vÅ¡etko, Äo sa na tÃ©my matching â€application/#â€œ objavÃ­. InÃ½mi slovami:

mosquitto_sub â€“ spÃºÅ¡Å¥a MQTT klienta v mÃ³de â€subscribeâ€œ
-h mqtt.hedurio.com â€“ hostname brokeru
-p 8883 â€“ port (8883 je Å¡tandardne TLS/SSL)
-u hedurio â€“ uÅ¾Ã­vateÄ¾skÃ© meno
-P qn3nyMYUPHTiigLrV94JRiAUXauE9F â€“ heslo
-t 'application/#' â€“ wildcard tÃ©ma, odchyÅ¥ vÅ¡etko pod â€application/â€¦â€œ
-v â€“ verbose, tzn. vypÃ­Å¡eÅ¡ nielen payload, ale aj nÃ¡zov tÃ©my

VÃ½sledok: v reÃ¡lnom Äase uvidÃ­Å¡ v terminÃ¡li kaÅ¾dÃº sprÃ¡vu (tÃ©ma + payload), ktorÃº ti brÃ¡na poÅ¡le na heduriacky MQTT broker. PrÃ­kaz niÄ neukladÃ¡ ani nepresmerovÃ¡va Äalej â€“ slÃºÅ¾i len na odpoÄÃºvanie (debug/monitoring). Pre produkciu/parsovanie si potom vytvorÃ­Å¡ vlastnÃ©ho subscriber-clienta (napr. v Node.js, Pythone...) a sprÃ¡vy po odchytenÃ­ uloÅ¾Ã­Å¡ Äi odoÅ¡leÅ¡ do DS.

# Ako vyzerÃ¡ mqqt arch ? 

broker 

â€“ centrÃ¡lny server, ktorÃ½ prijÃ­ma od publisherov sprÃ¡vy a doruÄuje ich subscriberom
â€“ starÃ¡ sa o smerovanie (â€routingâ€œ) podÄ¾a topicâ€reÅ¥azca, QoS, udrÅ¾iavanie stavov session, TTL, LWT atÄ.

Publisher (vydavateÄ¾)
â€“ akÃ½koÄ¾vek â€klientâ€œ (senzor, aplikÃ¡ciaâ€¦), ktorÃ½ dokÃ¡Å¾e sprÃ¡vy (payload) odoslaÅ¥ na broker
â€“ pri odoslanÃ­ definuje:
â€¢ topic (napr. sensors/temperature/room1)
â€¢ QoS (0, 1 alebo 2 â€“ garancia doruÄenia)
â€¢ retained flag (Äi broker mÃ¡ tÃºto sprÃ¡vu ponechaÅ¥ ako â€poslednÃº platnÃºâ€œ)

Subscriber (odoberateÄ¾)
â€“ klient, ktorÃ½ sa prihlÃ¡si k jednÃ©mu alebo viacerÃ½m topic-filterom (napr. sensors/# alebo actuators/+/set)
â€“ broker mu nÃ¡sledne doruÄuje kaÅ¾dÃº publikovanÃº sprÃ¡vu, ktorÃ¡ sa zhoduje s Ä¾ubovoÄ¾nÃ½m jeho filterom
â€“ pri prihlÃ¡senÃ­ si tieÅ¾ mÃ´Å¾e urÄiÅ¥ poÅ¾adovanÃ½ QoS ÃºroveÅˆ


NaÅ¡im â€publisheromâ€œ sÃº IoT trackery na endâ€device (LoRa senzory).
Trackery zaÅ¡lÃº uplink cez LoRaWAN brÃ¡nu do Hedurio network servera, ktorÃ½ vystavuje MQTT broker.
Trackery publikujÃº napr. na topic
application/123/device/456/uplink
s QoS=1, payloadom JSONu: {â€¦ GPS, timestamp â€¦}.
My (backend/subscriber) sa prihlÃ¡sime k topic-filtru
application/123/+/uplink
alebo jednoducho
application/#
a broker nÃ¡m zaÄne posielaÅ¥ vÅ¡etky uplinky zo vÅ¡etkÃ½ch deviceâ€id pod application/123.
Backend dokÃ¡Å¾e spracovaÅ¥ doruÄenÃ© sprÃ¡vy (parsovaÅ¥ JSON, ukladaÅ¥ do db, posielaÅ¥ notifikÃ¡cieâ€¦).

DÃ´leÅ¾itÃ© vlastnosti MQTT:

â€“ HierarchickÃ½ nÃ¡zov topicu rozdelenÃ½ lomÃ­tkami
â€“ Wildcardy: â€+â€œ (jedna ÃºroveÅˆ), â€#â€œ (viac ÃºrovnÃ­)
â€“ QoS 0,1,2 pre riadenie spoÄ¾ahlivosti
â€“ Retained sprÃ¡vy pre uchovÃ¡vanie poslednej hodnoty
â€“ Clean vs. persistent sessions (uloÅ¾enie nevyzdvihnutÃ½ch sprÃ¡v pri odpojenÃ­)
â€“ Å ifrovanie/TLS, autentifikÃ¡cia (uÅ¾Ã­vateÄ¾/heslo, certifikÃ¡ty)

â€“ Senzor = publisher â†’ broker
â€“ Broker = Hedurio MQTT server â†’ distribÃºcia podÄ¾a topic
â€“ Backend/appka/aktory = subscriber (alebo aj publisher downlinku) â†’ spracovanie Äi odoslanie prÃ­kazov

GeoFences je z PostGIS = virtuÃ¡lna geografickÃ¡ zÃ³na 

PrÃ­klad: HudobnÃ½ festival
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FESTIVAL AREA     â”‚  â† Geofence (polygon)
â”‚                     â”‚
â”‚  ğŸµ Stage          â”‚
â”‚  ğŸº Bar            â”‚
â”‚  ğŸš» WC             â”‚
â”‚                     â”‚
â”‚  ğŸ‘¤ Tracker1 INSIDE â”‚  âœ… OK
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         ğŸ‘¤ Tracker2 OUTSIDE  âš ï¸ ALERT!

Alert keÄ niekto:

OpustÃ­ povolenÃº zÃ³nu (dieÅ¥a sa stratilo)
VstÃºpi do zakÃ¡zanej zÃ³ny (VIP area bez prÃ­stupu)
Prejde do nebezpeÄnej zÃ³ny (backstage, strojovÅˆa)

Napr. 

Festival ma 3sceny ( Stage A,B,C )
- Dashboard zobrazÃ­: "Stage A: 245 Ä¾udÃ­, Stage B: 189 Ä¾udÃ­..."
Heatmapy a Å¡tatistiky 
time based geofencing 


vytvorenie geofence okolo podia 
- alert ked niekto opusti zÃ³nu 
detekcia kto je vo vnÃºtri geofence 
detekcia kto prave opustil geofence 

 Continuous Aggregates

âŒ Ak mÃ¡te < 10,000 zÃ¡znamov  
âŒ Ak dashboard refreshujÃº len 1-2 Ä¾udia obÄas  
âŒ Ak nepotrebujete agregÃ¡cie (staÄÃ­ len "kde je tracker prÃ¡ve teraz")
 
**Pre vÃ¡Å¡ projekt:**
- **ZatiaÄ¾ nepotrebujete** - mÃ¡te `latest_positions` view
- PridÃ¡te neskÃ´r ak budete robiÅ¥: "Å tatistiky pohybu za poslednÃ½ch 30 dnÃ­"

---

## 3ï¸âƒ£ Trackovanie dlhÅ¡ej trasy - Äo tÃ½m myslÃ­m?

Ãno! **PostGIS LINESTRING** = spojenie bodov do Äiary (trasa pohybu)

### **ÄŒo je to?**
```
GPS pozÃ­cie (POINT):
  ğŸ‘¤ â†’ ğŸ‘¤ â†’ ğŸ‘¤ â†’ ğŸ‘¤ â†’ ğŸ‘¤

Trasa (LINESTRING):
  ğŸ‘¤â”â”â”ğŸ‘¤â”â”â”ğŸ‘¤â”â”â”ğŸ‘¤â”â”â”ğŸ‘¤
  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      Jedna lÃ­nia!
```


PrÃ­klad hodne cool 

```cpp

-- ZÃ­skaj trasu trackera za poslednÃ½ch 6 hodÃ­n
SELECT 
    device_id,
    ST_AsGeoJSON(
        ST_MakeLine(location::geometry ORDER BY timestamp)
    )::json AS trail_geojson,
    MIN(timestamp) AS start_time,
    MAX(timestamp) AS end_time,
    COUNT(*) AS point_count
FROM positions
WHERE device_id = 'TestingTracker2'
  AND timestamp > NOW() - INTERVAL '6 hours'
GROUP BY device_id;

```

Output

{
  "type": "LineString",
  "coordinates": [
    [18.1614, 49.8216],
    [18.1618, 49.8215],
    [18.1622, 49.8214],
    [18.1625, 49.8212]
  ]
}

frontend 
// Vykreslenie trasy na mape
L.geoJSON(trail_geojson, {
    style: { color: '#FF0000', weight: 3 }
}).addTo(map);
```

VÃ½sledok:
```
Mapa:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         â”‚
â”‚      ğŸ—ºï¸                 â”‚
â”‚       â•±                 â”‚
â”‚      â•±  Trasa trackera â”‚
â”‚     â•±   (ÄervenÃ¡ Äiara)â”‚
â”‚    ğŸ‘¤ â† aktuÃ¡lna pozÃ­ciaâ”‚
â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


AnalÃ½za pohybu

CelkovÃ¡ vzdialenosÅ¥ prejdenÃ¡ za deÅˆ:

WITH trail AS (
    SELECT ST_MakeLine(location::geometry ORDER BY timestamp) AS line
    FROM positions
    WHERE device_id = 'TestingTracker2'
      AND timestamp::date = CURRENT_DATE
)
SELECT 
    ST_Length(line::geography) / 1000.0 AS distance_km
FROM trail;

priemernÃ¡ rÃ½chlost 

WITH movement AS (
    SELECT 
        timestamp,
        location,
        LAG(location::geometry) OVER (ORDER BY timestamp) AS prev_location,
        LAG(timestamp) OVER (ORDER BY timestamp) AS prev_time
    FROM positions
    WHERE device_id = 'TestingTracker2'
      AND timestamp > NOW() - INTERVAL '1 hour'
)
SELECT 
    AVG(
        ST_Distance(location::geometry, prev_location::geography) /  -- metre
        EXTRACT(EPOCH FROM (timestamp - prev_time)) * 3.6  -- km/h konverzia
    ) AS avg_speed_kmh,
    MAX(
        ST_Distance(location::geometry, prev_location::geography) /
        EXTRACT(EPOCH FROM (timestamp - prev_time)) * 3.6
    ) AS max_speed_kmh
FROM movement
WHERE prev_location IS NOT NULL;
```

**Output:**
```
avg_speed_kmh: 4.2 km/h  (prechodzka)
max_speed_kmh: 8.5 km/h  (rÃ½chla chÃ´dza)

kde stÃ¡l tracker dlhÅ¡ie neÅ¾ 5 minut 


WITH stationary_points AS (
    SELECT 
        timestamp,
        location,
        LAG(location::geometry) OVER (ORDER BY timestamp) AS prev_location,
        timestamp - LAG(timestamp) OVER (ORDER BY timestamp) AS time_diff
    FROM positions
    WHERE device_id = 'TestingTracker2'
      AND timestamp::date = CURRENT_DATE
)
SELECT 
    timestamp,
    ST_AsText(location::geometry) AS position,
    time_diff
FROM stationary_points
WHERE prev_location IS NOT NULL
  AND ST_Distance(location::geometry, prev_location::geography) < 50  -- < 50m pohyb
  AND time_diff > INTERVAL '5 minutes'
ORDER BY timestamp;
```

**Output:**
```
timestamp            | position                  | time_diff
---------------------|---------------------------|----------
2025-10-22 09:30:00  | POINT(18.1614 49.8216)   | 00:12:00
2025-10-22 14:15:00  | POINT(18.1625 49.8212)   | 00:08:30
```

â†’ "Tracker stÃ¡l pri sÃºradniciach X,Y na 12 minÃºt" (napr. obed, pauza)

---

#### **C) Timeline s trasou (vÃ¡Å¡ use-case!)**
```
Timeline slider:
[=====|=============]
      â†‘
  08:00-12:00

Mapa zobrazuje:
- AktuÃ¡lne pozÃ­cie (vÅ¡etky trackery)
- Trasa vybranÃ©ho trackera (08:00-12:00) jako ÄervenÃ¡ Äiara


Heat Maps 
UpozorniÅ¥ ked sa dve osoby priblÃ­Å¾ia 
movements patterns ( analÃ½za vzorcov pohybu ) 
movement patterns - Benefit: "90% Ä¾udÃ­ ide z hlavnÃ©ho vchodu cez Bar k Stage A" â†’ optimalizÃ¡cia infraÅ¡truktÃºry!
speed zones - detekcia abnormalnej rÃ½chlosti - Alert keÄ niekto beÅ¾Ã­ (moÅ¾nÃ½ incident/panika)
Dwell time analysis - Äas strÃ¡venÃ½ na mieste - kolko ludia stravia Äasu na mieste - pri food trucku ludia stoja primerne 8 minut -- pridaj ÄalÅ¡i truck
lost person detection - ziskaj poslednu znamu poziciu a priemernu rÃ½chlost/smer - vypoÄÃ­taj pravdepodobnÃº poziciu - nÃ¡sledne zobraz search area na mape a napr alert nejbliÃ½Å¡Ã­ stufftracker 


ÄŒo sa tÃ½ka TimescaleDB - minutovÃ© Å¡tatistiky ( pre lives dashboards ), auto refresh policy kaÅ¾dÃ½ch 30 sekund o vÃ½sledku dashborad querry bude super fast 

compression 
- automatickÃ¡ kompresia starÃ½ch dÃ¡t 
dÃ¡ta starÅ¡ie ako 7 dni --> komprimovanÃ© Äo nam da usportu miesta radovo o 90 percent 
nasledne dÃ¡ta starÅ¡ie ako napr 30 dni vymazaÅ¥ 
DOWNSAMPLING = po 30 dnoch, zmaÅ¾ detailne data, ponechat len hodinove agregÃ¡cie 
timesclaedb automaticky vytvÃ¡ra chunks 

# PodstatnÃ© prÃ­kazy pre Docker compose 

# âœ… SPUSTIÅ¤ kontajnery (pouÅ¾Ã­va existujÃºce images)
docker compose up -d

# âœ… ZASTAVIÅ¤ kontajnery (nepouÅ¡tia, data zostÃ¡vajÃº)
docker compose stop

# âœ… ZNOVA SPUSTIÅ¤ zastavenÃ© kontajnery
docker compose start

# âœ… REÅ TARTOVAÅ¤ beÅ¾iace kontajnery
docker compose restart

# âœ… ZASTAVIÅ¤ A ODSTRÃNIÅ¤ kontajnery (data v volumes ZOSTÃVAJÃš!)
docker compose down

# âš ï¸ ZASTAVIÅ¤, ODSTRÃNIÅ¤ kontajnery A VOLUMES (VYMAÅ½E DATA!)
docker compose down -v

ÄŒo pouzÃ­vaÅ¥ : 

PrvÃ© spustenie : docker compose up -d 
zastaviÅ¥ doÄasne : docker compose stop 
znova spustit : docker compose start 
reÅ¡tart po zmene kodu : docker compose restart 
zastavit a odstranit kontajnery : docker compose down 
vyÄistit vÅ¡etko vrÃ¡tane dÃ¡t : docker compose down -v 


# SledovaÅ¥ logy databÃ¡zy
docker-compose logs -f timescaledb

# SledovaÅ¥ logy vÅ¡etkÃ½ch sluÅ¾ieb
docker-compose logs -f

# Status kontajnerov
docker-compose ps

# ZobraziÅ¥ resources (CPU, RAM)
docker stats


# VyÄistiÅ¥ starÃ©/nepouÅ¾Ã­vanÃ© images
docker image prune -a

# VyÄistiÅ¥ vÅ¡etko nepouÅ¾Ã­vanÃ© (images, volumes, networks)
docker system prune -a --volumes

# ZobraziÅ¥ veÄ¾kosÅ¥ volumes
docker system df


docker exec -it tracker-db psql -U tracker_user -d tracker_db = priamo sa pripojiÅ¥ na ds 

SELECT * FROM devices;

REFRESH MATERIALIZED VIEW
SELECT * FROM latest_positions;

\q 

Testoavanie databÃ¡zy : 

REFRESH MATERIALIZED VIEW latest_positions;

2. AktuÃ¡lne pozÃ­cie:

SELECT * FROM latest_positions;

3. VzdialenosÅ¥ od centra BÃ­lovce:

SELECT 
    lp.device_id,
    d.device_name,
    lp.latitude,
    lp.longitude,
    ST_Distance(
        lp.location,
        ST_SetSRID(ST_MakePoint(18.0155, 49.7564), 4326)::geography
    ) / 1000.0 AS distance_km
FROM latest_positions lp
JOIN devices d ON lp.device_id = d.device_id;

Trasa trackera (LINESTRING)

SELECT 
    device_id,
    ST_AsText(ST_MakeLine(location::geometry ORDER BY timestamp)) AS trail_linestring,
    COUNT(*) AS point_count,
    MIN(timestamp) AS start_time,
    MAX(timestamp) AS end_time
FROM positions
WHERE device_id = '2cf7f1c05300063d'
GROUP BY device_id;

VzdialenosÅ¥ medzi po sebe idÃºcimi pozÃ­ciami:

WITH position_changes AS (
    SELECT 
        id,
        timestamp,
        location,
        LAG(location) OVER (ORDER BY timestamp) AS prev_location
    FROM positions
    WHERE device_id = '2cf7f1c05300063d'
)
SELECT 
    id,
    timestamp,
    ST_Distance(location, prev_location) AS distance_meters,
    EXTRACT(EPOCH FROM (timestamp - LAG(timestamp) OVER (ORDER BY timestamp))) AS time_diff_seconds
FROM position_changes
WHERE prev_location IS NOT NULL
ORDER BY timestamp;

 Database Å¡tatistiky:

 SELECT 
    'Devices' as table_name, COUNT(*) as count FROM devices
UNION ALL
SELECT 'Positions', COUNT(*) FROM positions
UNION ALL
SELECT 'Positions (24h)', COUNT(*) FROM positions WHERE timestamp > NOW() - INTERVAL '24 hours';

TimescaleDB chunks:

SELECT 
    chunk_name,
    range_start,
    range_end,
    pg_size_pretty(total_bytes) as size,
    compression_status
FROM timescaledb_information.chunks
WHERE hypertable_name = 'positions'
ORDER BY range_start DESC;
